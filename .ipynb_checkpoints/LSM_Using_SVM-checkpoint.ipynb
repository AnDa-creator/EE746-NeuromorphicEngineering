{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.078480Z",
     "start_time": "2021-11-26T06:10:52.257421Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcdI748AEYa8",
    "outputId": "c4fc5cc7-78d6-4127-8ce0-2e3548942304"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from numpy.random import binomial,shuffle,seed, choice\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "import CompactLSM\n",
    "\n",
    "seedval = 4 # for replicating results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reservoir Dimension set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.094482Z",
     "start_time": "2021-11-26T06:10:53.080484Z"
    }
   },
   "outputs": [],
   "source": [
    "nx = 5\n",
    "ny = 5\n",
    "nz = 5\n",
    "N = nx*ny*nz                                          # Reservoir size\n",
    "\n",
    "N_read = 10                                           # No. of Readout neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T12:37:57.345267Z",
     "start_time": "2021-10-23T12:37:57.330268Z"
    }
   },
   "source": [
    "Important constants related to LIF neuron and synaptic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.110484Z",
     "start_time": "2021-11-26T06:10:53.096486Z"
    }
   },
   "outputs": [],
   "source": [
    "global vrest, vth, t_refrac\n",
    "vrest, vth, t_refrac = 0, 20, 2\n",
    "\n",
    "tau_m = 32\n",
    "params_potential = {'C':1, 'g_L':1/tau_m, 'E_L':vrest, 'V_T':vth, 'R_p':t_refrac}\n",
    "\n",
    "Delay = 1 #constant delay for all synapses in ms\n",
    "\n",
    "tau_c = 64\n",
    "C_theta = 5\n",
    "del_C = 3\n",
    "n_bits = 8\n",
    "delta_c = 1\n",
    "params_conc = {'C_theta':C_theta, 'del_C':del_C, 'tau_c':64, 'nbits':n_bits, 'delta_c':delta_c}\n",
    "\n",
    "syn_string = \"static\"\n",
    "\n",
    "sampling_freq = 12.5 # in khz\n",
    "h = 1 # in ms\n",
    "α_w = 0.8\n",
    "time_params = {'h':h, 'Delay':Delay}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Reservoir Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.252539Z",
     "start_time": "2021-11-26T06:10:53.114487Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total synapse: 1130 ,E --> E : 769 ,E --> I: 105 ,I --> E/I: 256\n",
      "Total Connections: for neuron 64:1, [19, 62, 83, 84, 89, 93, 97, 109, 114, 118]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4000000000000004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the IDs of the neurons\n",
    "LSM_ID = np.zeros((nx,ny,nz),dtype=np.int64)\n",
    "l = 0\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        for k in range(nz):\n",
    "            LSM_ID[i,j,k] = l\n",
    "            l = l + 1\n",
    "\n",
    "# Storing the synapse connections, and creating the initial weight matrix\n",
    "\n",
    "k_prob = [0.45, 0.3, 0.6, 0.15]\n",
    "r_sq = 2**2\n",
    "\n",
    "W_arr = [3, 6, -2, -2]\n",
    "W_init = 3\n",
    "Weights_temp = np.zeros((N,N))\n",
    "\n",
    "N_in = int(N*0.8)\n",
    "neuron_type = [ int(i<N_in) for i in range(N)]\n",
    "seed(seedval)\n",
    "shuffle(neuron_type) # 1 for excitatory, 0 for inhibitory\n",
    "\n",
    "synapes = [dict() for i in range(N)]    # an array of dictonaries which store the location of neuron, \n",
    "                                        # type of neuron, and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N):\n",
    "    loc = CompactLSM.ID_to_ind(nx,ny,nz,l)\n",
    "    n_type = neuron_type[l]\n",
    "    cons = []\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            for k in range(nz):\n",
    "                if l != int(LSM_ID[i,j,k]):\n",
    "                    dist_sq = (loc[0]-i)**2 + (loc[1]-j)**2 + (loc[2]-k)**2\n",
    "                    k_probl = 0\n",
    "                    if n_type == 1:\n",
    "                      if neuron_type[int(LSM_ID[i,j,k])] == 1:\n",
    "                        k_probl = k_prob[0]\n",
    "                        W_init = W_arr[0]\n",
    "                      else:\n",
    "                        k_probl = k_prob[1]\n",
    "                        W_init = W_arr[1]\n",
    "                    else:\n",
    "                      if neuron_type[int(LSM_ID[i,j,k])] == 1:\n",
    "                        k_probl = k_prob[2]\n",
    "                        W_init = W_arr[2]\n",
    "                      else:\n",
    "                        k_probl = k_prob[3]\n",
    "                        W_init = W_arr[3]\n",
    "\n",
    "                    probability = k_probl* exp(-1*dist_sq/r_sq)\n",
    "#                     print(probability)\n",
    "                    check = binomial(1,probability)\n",
    "                    if check == 1:\n",
    "                        cons.append(int(LSM_ID[i,j,k]))\n",
    "                        Weights_temp[l,int(LSM_ID[i,j,k])] = W_init    \n",
    "    synapes[l] = {\"Location\":loc, \"Neuron_type\":n_type, \"connections\":cons}\n",
    "\n",
    "global Weights\n",
    "Weights = Weights_temp * α_w\n",
    "print(\"Total synapse:\", len(np.argwhere(Weights!=0)), \n",
    "        \",E --> E :\", len(np.argwhere(Weights==W_arr[0] * α_w)), \n",
    "        \",E --> I:\",len(np.argwhere(Weights==W_arr[1] * α_w)),\n",
    "        \",I --> E/I:\",len(np.argwhere(Weights==W_arr[2] * α_w)))\n",
    "i = 64\n",
    "print(\"Total Connections: for neuron {}:{}, {}\".format(i,synapes[i][\"Neuron_type\"],synapes[i][\"connections\"]) )\n",
    "Weights[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:37:08.001869Z",
     "start_time": "2021-10-23T13:37:07.984870Z"
    }
   },
   "source": [
    "Set Readout neuron initial Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.267930Z",
     "start_time": "2021-11-26T06:10:53.253542Z"
    }
   },
   "outputs": [],
   "source": [
    "All_labels = [str(x) for x in range(10)]\n",
    "# N_read = 10                                           # No. of Readout neurons\n",
    "\n",
    "Weights_temp_readOut = -8 + 16 * np.random.rand(N_read, N) # random weight initialization\n",
    "\n",
    "\n",
    "synapes_read = []        # an array of dictonaries which store the label of neuron, \n",
    "                                                      # and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N_read):\n",
    "    label = All_labels[l]\n",
    "    synapes_read.append(label)\n",
    "\n",
    "Weights_readOut = Weights_temp_readOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.283568Z",
     "start_time": "2021-11-26T06:10:53.269925Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating file location and label arrays for train and validate\n",
    "\n",
    "base = 'PreProcessing/trainBSA'\n",
    "os.listdir(base)\n",
    "\n",
    "All_Labels = []\n",
    "file_name_List = []\n",
    "\n",
    "for human in os.listdir(base):\n",
    "    base_up = base + '/' + human\n",
    "    for train_sample in os.listdir(base_up):\n",
    "        train_Label = train_sample[0:2]\n",
    "        file_loc = base_up + '/' + train_sample\n",
    "        file_name_List.append(file_loc)\n",
    "        All_Labels.append(train_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.298614Z",
     "start_time": "2021-11-26T06:10:53.285572Z"
    }
   },
   "outputs": [],
   "source": [
    "L = 78\n",
    "Fin = 4\n",
    "reservoir_ID = [i for i in range(N)]\n",
    "seed(seedval)\n",
    "Input_CXNs = choice(reservoir_ID, size = (L,Fin))\n",
    "sign_win_matrix = (binomial(1,1/2, size = (L, Fin)) - 0.5)*2\n",
    "# Input_CXNs * sign_win_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding input neurons to reservoir current and then using the spike train to find the current input to the reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.314616Z",
     "start_time": "2021-11-26T06:10:53.300615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Reservoir = 5 X 5 X 5 ,Total total neurons = 125\n",
      "Total no.of read out neurons = 10\n"
     ]
    }
   ],
   "source": [
    "# print(\"Input neurons =\",L)\n",
    "print(\"Size of Reservoir =\",nx,\"X\",ny,\"X\",nz,\",Total total neurons =\",N)\n",
    "print(\"Total no.of read out neurons =\",N_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T06:10:53.900516Z",
     "start_time": "2021-11-26T06:10:53.315616Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (6.4 * 3, 4.8),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'medium',\n",
    "         'ytick.labelsize':'medium',\n",
    "         'figure.titlesize':'xx-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-26T06:10:52.261Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############### Training ###################\n",
    "Input_gen_func = CompactLSM.Input_current_gen(file_name_List,\n",
    "                                                syn_string,\n",
    "                                                N,\n",
    "                                                time_params,\n",
    "                                                Input_CXNs,\n",
    "                                                sign_win_matrix,\n",
    "                                                training=True,\n",
    "                                                train_Labels=All_Labels)\n",
    "NUM_INPUTS = len(All_Labels)\n",
    "\n",
    "X = np.zeros((NUM_INPUTS,N))\n",
    "Y = np.zeros((NUM_INPUTS,))\n",
    "\n",
    "for i in range(NUM_INPUTS):\n",
    "    In_app, L, M, Label, input_num, In_spikes = next(\n",
    "        Input_gen_func)  # Generates next input\n",
    "\n",
    "    [Reservoir_potential, Reservoir_Spikes\n",
    "        ] = CompactLSM.reservoir_solver(N, Delay, synapes, M, h, In_app,\n",
    "                                        params_potential, Weights, syn_string)\n",
    "    \n",
    "\n",
    "    X[i,:] = np.sum(Reservoir_Spikes,axis=1)\n",
    "    Y[i] = Label\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=seedval)\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear', verbose=True) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print('Training Completed \\n')\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_pred = clf.predict(X_val)\n",
    "\n",
    "\n",
    "Acc = accuracy_score(Y_val, Y_pred)\n",
    "\n",
    "print('Validation Completed \\n')\n",
    "\n",
    "display_string = \"Accuracy:{}\".format(Acc * 100)\n",
    "print(display_string)\n",
    "\n",
    "cm_validate = confusion_matrix(Y_val,\n",
    "                                   Y_pred,\n",
    "                                   labels=[i for i in range(10)])\n",
    "disp_validate = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_validate, display_labels=[i for i in range(10)])\n",
    "disp_validate.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T05:53:39.434642Z",
     "start_time": "2021-11-26T05:53:39.418639Z"
    }
   },
   "source": [
    "### Network Learning without reservoir, only input spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-26T06:10:52.267Z"
    }
   },
   "outputs": [],
   "source": [
    "############### Training ###################\n",
    "Input_gen_func = CompactLSM.Input_current_gen(file_name_List,\n",
    "                                                syn_string,\n",
    "                                                N,\n",
    "                                                time_params,\n",
    "                                                Input_CXNs,\n",
    "                                                sign_win_matrix,\n",
    "                                                training=True,\n",
    "                                                train_Labels=All_Labels)\n",
    "NUM_INPUTS = len(All_Labels)\n",
    "\n",
    "X = np.zeros((NUM_INPUTS,78))\n",
    "Y = np.zeros((NUM_INPUTS,))\n",
    "\n",
    "for i in range(NUM_INPUTS):\n",
    "    In_app, L, M, Label, input_num, In_spikes = next(\n",
    "        Input_gen_func)  # Generates next input\n",
    "    \n",
    "\n",
    "    X[i,:] = np.sum(In_spikes,axis=1)\n",
    "    Y[i] = Label\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=seedval)\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear', verbose=True) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print('Training Completed \\n')\n",
    "\n",
    "#Predict the response for test dataset\n",
    "Y_pred = clf.predict(X_val)\n",
    "\n",
    "\n",
    "Acc = accuracy_score(Y_val, Y_pred)\n",
    "\n",
    "print('Validation Completed \\n')\n",
    "\n",
    "display_string = \"Accuracy:{}\".format(Acc * 100)\n",
    "print(display_string)\n",
    "\n",
    "cm_validate = confusion_matrix(Y_val,\n",
    "                                   Y_pred,\n",
    "                                   labels=[i for i in range(10)])\n",
    "disp_validate = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm_validate, display_labels=[i for i in range(10)])\n",
    "disp_validate.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb34221c29cbd393528f59737984b7cee90fecb74dfd32a425a37477f31f3c8a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
