{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:42:01.314928Z",
     "start_time": "2021-10-15T14:41:53.522176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow_core._api.v2.version' from 'C:\\\\Users\\\\anura\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow_core\\\\_api\\\\v2\\\\version\\\\__init__.py'> \n",
      " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from numpy.random import binomial\n",
    "from random import shuffle\n",
    "\n",
    "nx = 5\n",
    "ny = 5\n",
    "nz = 5\n",
    "N = nx*ny*nz\n",
    "print(tf.version,'\\n', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:42:04.306467Z",
     "start_time": "2021-10-15T14:42:01.318928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the neurons\n",
    "LSM_neurons = np.zeros((nx,ny,nz),np.float64)\n",
    "LSM_neurons = tf.convert_to_tensor(LSM_neurons,dtype=tf.float64)\n",
    "# print(LSM_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:42:04.322567Z",
     "start_time": "2021-10-15T14:42:04.308466Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing the IDs of the neurons\n",
    "LSM_ID = np.zeros((nx,ny,nz),dtype=np.int64)\n",
    "l = 0\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            LSM_ID[i,j,k] = l\n",
    "            l = l + 1;\n",
    "\n",
    "LSM_ID = tf.convert_to_tensor(LSM_ID,dtype=tf.int64)\n",
    "# print(LSM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:42:04.744088Z",
     "start_time": "2021-10-15T14:42:04.324569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing the synapse connections\n",
    "k_prob = 1\n",
    "r_sq = 1**2\n",
    "\n",
    "N_in = int(N*0.8)\n",
    "neuron_type = [ int(i<N_in) for i in range(N)]\n",
    "shuffle(neuron_type) # 1 for excitatory, 0 for inhibitory\n",
    "\n",
    "synapes = [dict() for i in range(N)]    # an array of dictonaries which store the location of neuron, type of neuron and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N):\n",
    "    x = int(l/25)\n",
    "    y = int( (l-25*x) / 5)\n",
    "    z = int(l%5)\n",
    "    loc = [x,y,z]\n",
    "    n_type = neuron_type[l]\n",
    "    cons = []\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            for k in range(nz):\n",
    "                dist_sq = (x-i)**2 + (y-j)**2 + (z-k)**2\n",
    "                probability = k_prob* exp(-1*dist_sq/r_sq)\n",
    "                check = binomial(1,probability)\n",
    "                if check == 1:\n",
    "                    cons.append(int(LSM_ID[i,j,k]))\n",
    "    \n",
    "    synapes[l] = {\"Location\":loc, \"Neuron_type\":n_type, \"connections\":cons}\n",
    "\n",
    "# print(synapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:42:09.863057Z",
     "start_time": "2021-10-15T14:42:04.746089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\anaconda3\\lib\\site-packages\\Cython\\Distutils\\old_build_ext.py:41: UserWarning: Cython.Distutils.old_build_ext does not properly handle dependencies and is deprecated.\n",
      "  \"Cython.Distutils.old_build_ext does not properly handle dependencies \"\n"
     ]
    }
   ],
   "source": [
    "from brian2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIF Neuron\n",
    "Converted from MATLAB.  Modified version of LIF solver for HW1, with N neurons and refractory period added, solves just a single timestep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:42:09.879061Z",
     "start_time": "2021-10-15T14:42:09.866060Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "params = {'C':300, 'g_L':30, 'E_L':-70, 'V_T':20, 'R_p':2}\n",
    "C, g_L, E_L, V_T, R_p = params.values()\n",
    "def LIF(V_neuron_prev,I_input_prev,I_input_next,N,h,index_next,index_prev_spike, params):\n",
    "    C, g_L, E_L, V_T, R_p = params.values()\n",
    "    R_p_ind = tf.math.ceil(R_p/h)\n",
    "    \n",
    "    V_neuron_next = E_L*tf.ones([N,1], dtype='float');Spike_next = tf.zeros([N,1], dtype='float')\n",
    "    \n",
    "    k1 = (1/C)*(-g_L*(V_neuron_prev-E_L)+I_input_prev);\n",
    "    V_temp = V_neuron_prev + k1*h/2;\n",
    "    I_temp = I_input_prev/2 + I_input_next/2;\n",
    "    V_temp = V_neuron_prev + k2*h;\n",
    "    \n",
    "    for i in range(N):\n",
    "        if index_next-index_prev_spike < R_p_ind:\n",
    "            V_neuron_next[i] = E_L;\n",
    "        elif V_temp[i] < V_T:\n",
    "            V_neuron_next[i] = V_temp[i];\n",
    "        else:\n",
    "            Spike_next[i] = 1;\n",
    "            V_neuron_next[i] = V_temp[i];\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplified model in paper(IEEE ZHANG et al)\n",
    "Effect of Synaptic models **Section V(A), eqns -- 19, 20, 21**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:52:45.654766Z",
     "start_time": "2021-10-15T14:52:45.642766Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from exceptions import ValueError\n",
    "global vrest, vth, t_refrac\n",
    "vrest, vth, t_refrac = -70, 20, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:55:33.774904Z",
     "start_time": "2021-10-15T14:55:33.751903Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def syn_res(syn_string, time_ind, spike_timing_mat, h, type_syn=None):\n",
    "    \n",
    "    if syn_string == \"static\":\n",
    "        result_mat = [1 if time_ind == a_spike else 0 for a_spike in spike_timing_mat]\n",
    "        return result_mat\n",
    "    elif syn_string == \"first-order\":\n",
    "        tau_s = 4 * h # Given in paper\n",
    "        result_mat = (1/tau_s) * (np.exp(- (time_ind - spike_timing_mat)/tau_s) \n",
    "        * np.heaviside(time_ind - spike_timing_mat))\n",
    "        return result_mat\n",
    "    elif syn_string == \"second-order\":\n",
    "        if type_syn is None:\n",
    "            raise ValueError('type required')\n",
    "        elif type_syn == 'Exc':\n",
    "            tau_s1, tau_s2 = 4, 8\n",
    "        elif type_syn == 'Inh':\n",
    "            tau_s1, tau_s2 = 4, 2\n",
    "        else:\n",
    "            raise ValueError('type invalid')\n",
    "        result_mat = ((1/(tau_s1 - tau_s2)) * np.exp(- (time_ind - spike_timing_mat)/tau_s1)\n",
    "                      * np.heaviside(time_ind - spike_timing_mat)\n",
    "                      - ((1/(tau_s1 - tau_s2)) * np.exp(- (time_ind - spike_timing_mat)/tau_s2)\n",
    "                      * np.heaviside(time_ind - spike_timing_mat)))\n",
    "        \n",
    "        return result_mat\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models for implementing proposed learning rule **Section IV(c), eqns -- 12, 13, 14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def LIF_rsp_one(neuron_id,Weight_mat, Vm_prev, FanIn_list, syn_string, \n",
    "                tau_m, spikeTime_mat, Delay_mat, it_prev, h, time_ind, **kwargs):\n",
    "    global vrest, vth\n",
    "    spike_happened = 0\n",
    "    V_temp = Vm_prev  - Vm_prev/tau_m + it_prev\n",
    "    for i in FanIn_list:\n",
    "        V_temp += Weight_mat[i] * syn_res(syn_string, time_ind, spikeTime_mat[:, i] + Delay_mat[i], h) \n",
    "    if time_ind - spikeTime_mat[neuron_id][-1] <= tf.math.ceil(t_refrac/h) \n",
    "        V_temp = vrest\n",
    "    elif V_temp > vth:\n",
    "        spikeTime_mat[time_ind, neuron_id] = 1\n",
    "        V_temp = vrest\n",
    "    else:\n",
    "        pass\n",
    "    return V_temp\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight learning by calculation of Digitized Calcium concentration updation, **Equations 15 , 16 in IEEE paper**<br>\n",
    "Incomplete, have to read section **III(A), III(B)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_learner(tau_c, last_conc, time_ind, this_neuron_spiked):\n",
    "    new_conc = last_conc - last_conc/tau_c + np.sum(np.heaviside(time_ind - this_neuron_spiked))\n",
    "    ## Need to implement the learning rule here \n",
    "    return new_conc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted from **MATLAB assignment 3 Q2** neuron solver <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_solver(N, Connect_mat, M, h, I_app,threshold **kwargs):\n",
    "    global vrest, vth\n",
    "    I_syn = tf.zeros(N,M);             I_total = tf.zeros(N,M);\n",
    "    V_neurons = vrest*tf.ones(N,M);    Spikes = tf.zeros(N,M);\n",
    "    Calcium_conc = tf.zeros(N,M);      weight_mat = tf.ones(N,M);\n",
    "    tau_m, syn_string, h = 32, \"static\", 0.5\n",
    "    \n",
    "    for i in range(1,M):\n",
    "        I_total[:,i] = I_app[:,i] + I_syn[:,i];\n",
    "        for j in range(N):\n",
    "            V_neuron[j,i] = LIF_rsp_one(j, Weight_mat[j], V_neuron[j-1,i], Connect_mat[j], syn_string,\n",
    "                                       tau_m, Spikes, Delay_mat, I_total[:,i-1], h, time_ind=i,\n",
    "                                       Calcium_conc = Calcium_conc)\n",
    "    \n",
    "    ## The parts done after this in matlab code not sure\n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb34221c29cbd393528f59737984b7cee90fecb74dfd32a425a37477f31f3c8a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
