{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:38.932482Z",
     "start_time": "2021-10-24T08:14:38.916854Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcdI748AEYa8",
    "outputId": "c4fc5cc7-78d6-4127-8ce0-2e3548942304"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from numpy.random import binomial\n",
    "from random import shuffle\n",
    "from random import seed\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import CompactLSM\n",
    "\n",
    "seed(4) # for replicating results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reservoir Dimension set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:39.701792Z",
     "start_time": "2021-10-24T08:14:39.686164Z"
    }
   },
   "outputs": [],
   "source": [
    "nx = 5\n",
    "ny = 5\n",
    "nz = 5\n",
    "N = nx*ny*nz                                          # Reservoir size\n",
    "\n",
    "N_read = 10                                           # No. of Readout neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T12:37:57.345267Z",
     "start_time": "2021-10-23T12:37:57.330268Z"
    }
   },
   "source": [
    "Important constants related to LIF neuron and synaptic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:40.219535Z",
     "start_time": "2021-10-24T08:14:40.188275Z"
    }
   },
   "outputs": [],
   "source": [
    "global vrest, vth, t_refrac\n",
    "vrest, vth, t_refrac = 0, 20, 2\n",
    "\n",
    "tau_m = 32\n",
    "params_potential = {'C':1, 'g_L':1/tau_m, 'E_L':vrest, 'V_T':vth, 'R_p':t_refrac}\n",
    "\n",
    "Delay = 1 #constant delay for all synapses in ms\n",
    "\n",
    "tau_c = 64\n",
    "C_theta = 10\n",
    "del_C = 2\n",
    "n_bits = 8\n",
    "delta_c = 1\n",
    "params_conc = {'C_theta':C_theta, 'del_C':del_C, 'tau_c':64, 'nbits':n_bits, 'delta_c':delta_c}\n",
    "\n",
    "syn_string = \"first-order\"\n",
    "\n",
    "sampling_freq = 12.5 # in khz\n",
    "h = 1/sampling_freq # in ms\n",
    "\n",
    "time_params = {'h':h, 'Delay':Delay}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Reservoir Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:40.863113Z",
     "start_time": "2021-10-24T08:14:40.737296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing the IDs of the neurons\n",
    "LSM_ID = np.zeros((nx,ny,nz),dtype=np.int64)\n",
    "l = 0\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        for k in range(nz):\n",
    "            LSM_ID[i,j,k] = l\n",
    "            l = l + 1\n",
    "\n",
    "# Storing the synapse connections, and creating the initial weight matrix\n",
    "seed(1)\n",
    "k_prob = [0.45, 0.3, 0.6, 0.15]\n",
    "r_sq = 2**2\n",
    "\n",
    "W_arr = [3, 6, -2, -2]\n",
    "W_init = 3\n",
    "Weights_temp = np.zeros((N,N))\n",
    "\n",
    "N_in = int(N*0.8)\n",
    "neuron_type = [ int(i<N_in) for i in range(N)]\n",
    "shuffle(neuron_type) # 1 for excitatory, 0 for inhibitory\n",
    "\n",
    "synapes = [dict() for i in range(N)]    # an array of dictonaries which store the location of neuron, \n",
    "                                        # type of neuron, and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N):\n",
    "    loc = CompactLSM.ID_to_ind(nx,ny,nz,l)\n",
    "    n_type = neuron_type[l]\n",
    "    cons = []\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            for k in range(nz):\n",
    "                if l != int(LSM_ID[i,j,k]):\n",
    "                    dist_sq = (loc[0]-i)**2 + (loc[1]-j)**2 + (loc[2]-k)**2\n",
    "                    k_probl = 0\n",
    "                    if n_type == 1:\n",
    "                      if neuron_type[int(LSM_ID[i,j,k])] == 1:\n",
    "                        k_probl = k_prob[0]\n",
    "                        W_init = W_arr[0]\n",
    "                      else:\n",
    "                        k_probl = k_prob[1]\n",
    "                        W_init = W_arr[1]\n",
    "                    else:\n",
    "                      if neuron_type[int(LSM_ID[i,j,k])] == 1:\n",
    "                        k_probl = k_prob[2]\n",
    "                        W_init = W_arr[2]\n",
    "                      else:\n",
    "                        k_probl = k_prob[3]\n",
    "                        W_init = W_arr[3]\n",
    "\n",
    "                    probability = k_probl* exp(-1*dist_sq/r_sq)\n",
    "#                     print(probability)\n",
    "                    check = binomial(1,probability)\n",
    "                    if check == 1:\n",
    "                        cons.append(int(LSM_ID[i,j,k]))\n",
    "                        Weights_temp[l,int(LSM_ID[i,j,k])] = W_init    \n",
    "    synapes[l] = {\"Location\":loc, \"Neuron_type\":n_type, \"connections\":cons}\n",
    "\n",
    "global Weights\n",
    "Weights = Weights_temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-23T13:37:08.001869Z",
     "start_time": "2021-10-23T13:37:07.984870Z"
    }
   },
   "source": [
    "Set Readout neuron initial Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:41.380900Z",
     "start_time": "2021-10-24T08:14:41.365268Z"
    }
   },
   "outputs": [],
   "source": [
    "All_labels = [str(x) for x in range(10)]\n",
    "# N_read = 10                                           # No. of Readout neurons\n",
    "W_init_read = .01                                      # Initial weight, equal for all, update with learning\n",
    "Weights_temp_readOut = W_init_read*np.ones((N_read, N), dtype='float')\n",
    "\n",
    "\n",
    "synapes_read = []        # an array of dictonaries which store the label of neuron, \n",
    "                                                      # and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N_read):\n",
    "    label = All_labels[l]\n",
    "    synapes_read.append(label)\n",
    "\n",
    "Weights_readOut = Weights_temp_readOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:41.804486Z",
     "start_time": "2021-10-24T08:14:41.773220Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating file location and label arrays for train and validate\n",
    "\n",
    "base = 'PreProcessing/trainBSA'\n",
    "os.listdir(base)\n",
    "\n",
    "train_Labels = []\n",
    "file_name_List = []\n",
    "\n",
    "for human in os.listdir(base):\n",
    "    base_up = base + '/' + human\n",
    "    for train_sample in os.listdir(base_up):\n",
    "        train_Label = train_sample[0:2]\n",
    "        file_loc = base_up + '/' + train_sample\n",
    "        file_name_List.append(file_loc)\n",
    "        train_Labels.append(train_Label)\n",
    "\n",
    "seedval = 4\n",
    "\n",
    "seed(seedval)\n",
    "shuffle(train_Labels)\n",
    "seed(seedval)\n",
    "shuffle(file_name_List)\n",
    "\n",
    "total_size = len(train_Labels)\n",
    "train_size = int(total_size*0.8)\n",
    "\n",
    "validate_Labels = train_Labels[train_size:total_size]\n",
    "validate_file_list = file_name_List[train_size:total_size]\n",
    "\n",
    "train_Labels = train_Labels[0:train_size]\n",
    "train_file_list = file_name_List[0:train_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding input neurons to reservoir current and then using the spike train to find the current input to the reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:42.684128Z",
     "start_time": "2021-10-24T08:14:42.668493Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Input neurons =\",L)\n",
    "# print(\"Size of Reservoir =\",nx,\"X\",ny,\"X\",nz,\",Total total neurons =\",N)\n",
    "# print(\"Total no.of read out neurons =\",N_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-24T08:14:43.138600Z",
     "start_time": "2021-10-24T08:14:43.122973Z"
    }
   },
   "outputs": [],
   "source": [
    "# if need to exit training load last trained weights\n",
    "# load_idx = 0\n",
    "# Weights_readOut_fromCsv = pd.read_csv(\"Weights/weights_epoch{}.csv\".format(load_idx), sep=\",\", header=None)\n",
    "# Weights_readOut = Weights_readOut_fromCsv.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solving the reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-24T08:14:44.461Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Epoch: 1, Training input: 116, Classified label: 7, Actual label: 7"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "EPOCHS = 200 # From paper\n",
    "\n",
    "Weights_epoch_save = []\n",
    "prediction_rate = np.zeros((EPOCHS,))\n",
    "Validation_rate = np.zeros((EPOCHS,))\n",
    "for epoch in range(500):\n",
    "    print(\"=\"*50)\n",
    "    correct_predictions = 0\n",
    "\n",
    "    Input_gen_func = CompactLSM.Input_current_gen(train_file_list, syn_string, N, time_params, training=True, train_Labels=train_Labels)\n",
    "    NUM_INPUTS = len(train_Labels)\n",
    "    \n",
    "    for i in range(NUM_INPUTS):\n",
    "        In_app, L, M, train_Label,input_num = next(Input_gen_func)      # Generates next input   \n",
    "\n",
    "        [Reservoir_potential, Reservoir_Spikes] = CompactLSM.reservoir_solver(N, Delay, synapes, M, h, In_app, \n",
    "                                                                          params_potential, Weights, syn_string)\n",
    "        \n",
    "        Readout_potential, Readout_Spikes, trained_weights = CompactLSM.readOut_response(N_read,N, Delay, synapes, M,\n",
    "                                                                                         h, Reservoir_Spikes, \n",
    "                                                                                         params_potential,params_conc,\n",
    "                                                                                         Weights_readOut,syn_string,\n",
    "                                                                                         training=True,train_ids=[train_Label])\n",
    "        \n",
    "        class_out_label, class_out_idx= CompactLSM.classifier(Readout_Spikes,synapes_read)\n",
    "        Weights_readOut = trained_weights\n",
    "        \n",
    "        display_string = \"Epoch: {}, Training input: {}, Classified label: {}, Actual label: {}\".format(\n",
    "            epoch + 1, i + 1, class_out_label, train_Label)\n",
    "        print(\"\\r\"+display_string,end=\"\")\n",
    "\n",
    "    \n",
    "        if int(class_out_label) == int(train_Label):\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    Weights_epoch_save.append(Weights_readOut)\n",
    "    prediction_rate[epoch] = correct_predictions/NUM_INPUTS\n",
    "    \n",
    "    path = \"Weights/\"; file = \"weights_epoch{}.csv\".format(epoch)\n",
    "    pd.DataFrame(Weights_readOut).to_csv(path + file)\n",
    "    display_string = \"Last Epoch Prediction rate:{}\".format(prediction_rate[epoch] * 100)\n",
    "    print(\"\\n\" + display_string)\n",
    "    print(\"*\"*50)\n",
    "    # Validation\n",
    "    Input_gen_func = CompactLSM.Input_current_gen(validate_file_list, syn_string, N, time_params, training=True, train_Labels=validate_Labels)\n",
    "    NUM_INPUTS = len(validate_Labels)\n",
    "\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for i in range(NUM_INPUTS):\n",
    "        In_app, L, M, validate_Label,input_num = next(Input_gen_func)      # Generates next input   \n",
    "\n",
    "        [Reservoir_potential, Reservoir_Spikes] = CompactLSM.reservoir_solver(N, Delay, synapes, M, h, In_app, \n",
    "                                                                            params_potential, Weights, syn_string)\n",
    "\n",
    "        Readout_potential, Readout_Spikes, trained_weights = CompactLSM.readOut_response(N_read,N, Delay, synapes, M,\n",
    "                                                                                            h, Reservoir_Spikes, \n",
    "                                                                                            params_potential,params_conc,\n",
    "                                                                                            Weights_readOut,syn_string,\n",
    "                                                                                            training=False,train_ids=[validate_Label])\n",
    "\n",
    "        class_out_label, class_out_idx= CompactLSM.classifier(Readout_Spikes,synapes_read)\n",
    "#         Weights_readOut = trained_weights\n",
    "\n",
    "        display_string = \"Validate input: {}, Classified label: {}, Actual label: {}\".format(\n",
    "            i + 1, class_out_label, validate_Label)\n",
    "        print(\"\\r\"+display_string,end=\"\")\n",
    "\n",
    "\n",
    "        if int(class_out_label) == int(validate_Label):\n",
    "            correct_predictions += 1\n",
    "\n",
    "    Validation_rate[epoch] = correct_predictions/NUM_INPUTS\n",
    "    display_string = \"Last Epoch validation rate:{}\".format(Validation_rate[epoch]*100)\n",
    "    print(\"\\n\" + display_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb34221c29cbd393528f59737984b7cee90fecb74dfd32a425a37477f31f3c8a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
