{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:18.400774Z",
     "start_time": "2021-10-21T10:55:12.001351Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcdI748AEYa8",
    "outputId": "c4fc5cc7-78d6-4127-8ce0-2e3548942304"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from numpy.random import binomial\n",
    "from random import shuffle\n",
    "from random import seed\n",
    "\n",
    "nx = 5\n",
    "ny = 5\n",
    "nz = 5\n",
    "N = nx*ny*nz\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('PreProcessedData.csv', sep=\",\", header=None)\n",
    "data_as_numpy = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:21.389937Z",
     "start_time": "2021-10-21T10:55:18.402775Z"
    },
    "id": "UqvdmsHeEYbA"
   },
   "outputs": [],
   "source": [
    "# Storing the IDs of the neurons\n",
    "LSM_ID = np.zeros((nx,ny,nz),dtype=np.int64)\n",
    "l = 0\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        for k in range(nz):\n",
    "            LSM_ID[i,j,k] = l\n",
    "            l = l + 1\n",
    "\n",
    "LSM_ID = tf.convert_to_tensor(LSM_ID,dtype=tf.int64)\n",
    "# print(LSM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:21.404939Z",
     "start_time": "2021-10-21T10:55:21.393940Z"
    },
    "id": "ei7ZghhuEYbA"
   },
   "outputs": [],
   "source": [
    "def ID_to_ind(nx,ny,nz,ID):\n",
    "    x = int(ID/(ny*nz))\n",
    "    y = int( (ID-(ny*nz)*x) / nz)\n",
    "    z = int(ID%nz)\n",
    "    return [x, y, z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.011223Z",
     "start_time": "2021-10-21T10:55:21.406940Z"
    },
    "id": "4R3g7UJkEYbB"
   },
   "outputs": [],
   "source": [
    "# Storing the synapse connections, and creating the initial weight matrix\n",
    "seed(1)\n",
    "k_prob = [0.45, 0.3, 0.6, 0.15]\n",
    "r_sq = 2**2\n",
    "\n",
    "W_arr = [3, 6, -2, -2]\n",
    "W_init = 3\n",
    "Weights_temp = np.zeros((N,N))\n",
    "\n",
    "N_in = int(N*0.8)\n",
    "neuron_type = [ int(i<N_in) for i in range(N)]\n",
    "shuffle(neuron_type) # 1 for excitatory, 0 for inhibitory\n",
    "\n",
    "synapes = [dict() for i in range(N)]    # an array of dictonaries which store the location of neuron, type of neuron, and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N):\n",
    "    loc = ID_to_ind(nx,ny,nz,l)\n",
    "    n_type = neuron_type[l]\n",
    "    cons = []\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            for k in range(nz):\n",
    "                if l != int(LSM_ID[i,j,k]):\n",
    "                    dist_sq = (loc[0]-i)**2 + (loc[1]-j)**2 + (loc[2]-k)**2\n",
    "                    k_probl = 0\n",
    "                    if n_type == 1:\n",
    "                      if neuron_type[int(LSM_ID[i,j,k])] == 1:\n",
    "                        k_probl = k_prob[0]\n",
    "                        W_init = W_arr[0]\n",
    "                      else:\n",
    "                        k_probl = k_prob[1]\n",
    "                        W_init = W_arr[1]\n",
    "                    else:\n",
    "                      if neuron_type[int(LSM_ID[i,j,k])] == 1:\n",
    "                        k_probl = k_prob[2]\n",
    "                        W_init = W_arr[2]\n",
    "                      else:\n",
    "                        k_probl = k_prob[3]\n",
    "                        W_init = W_arr[3]\n",
    "\n",
    "                    probability = k_probl* exp(-1*dist_sq/r_sq)\n",
    "                    check = binomial(1,probability)\n",
    "                    if check == 1:\n",
    "                        cons.append(int(LSM_ID[i,j,k]))\n",
    "                        Weights_temp[l,int(LSM_ID[i,j,k])] = W_init    \n",
    "    synapes[l] = {\"Location\":loc, \"Neuron_type\":n_type, \"connections\":cons}\n",
    "\n",
    "global Weights\n",
    "Weights = tf.convert_to_tensor(Weights_temp,dtype=tf.float64)\n",
    "Delay = 1 #constant delay for all synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T11:00:10.792636Z",
     "start_time": "2021-10-21T11:00:10.785637Z"
    },
    "code_folding": [],
    "id": "m9b2jK7zEYbE"
   },
   "outputs": [],
   "source": [
    "# from exceptions import ValueError\n",
    "global vrest, vth, t_refrac\n",
    "vrest, vth, t_refrac = 0, 20, 2\n",
    "\n",
    "tau_m = 32\n",
    "params_potential = {'C':1, 'g_L':1/tau_m, 'E_L':vrest, 'V_T':vth, 'R_p':t_refrac}\n",
    "\n",
    "tau_c = 64\n",
    "C_theta = 5\n",
    "del_C = 3\n",
    "n_bits = 3\n",
    "delta_c = 1\n",
    "params_conc = {'C_theta':C_theta, 'del_C':del_C, 'tau_c':64, 'nbits':n_bits, 'delta_c':delta_c}\n",
    "C_theta, del_c, tau_c, nbits,delta_c = params_conc.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULdWIAwkEYbF"
   },
   "source": [
    "#### LIF Neuron single step solver\n",
    "Converted from MATLAB.  Modified version of LIF solver for HW1, with N neurons and refractory period added, solves just a single timestep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.366250Z",
     "start_time": "2021-10-21T10:55:29.347247Z"
    },
    "code_folding": [],
    "id": "uKu51rLoEYbG"
   },
   "outputs": [],
   "source": [
    "def LIF(V_neuron_prev,I_input_prev,I_input_next,N,h,index_next,index_prev_spike, params):\n",
    "    C, g_L, E_L, V_T, R_p = params.values()\n",
    "    R_p_ind = tf.math.ceil(R_p/h)\n",
    "    \n",
    "    V_neuron_next = tf.math.scalar_mul(E_L,tf.ones((N,), dtype='float'))\n",
    "    Spike_next = tf.zeros((N,), dtype='int64')\n",
    "    \n",
    "    k1 = (1/C)*(-g_L*(V_neuron_prev-E_L)+I_input_prev)\n",
    "    V_temp = V_neuron_prev + k1*h/2\n",
    "    I_temp = I_input_prev/2 + I_input_next/2\n",
    "    k2 = (1/C)*(-g_L*(V_temp-E_L)+I_temp)\n",
    "    V_temp = V_neuron_prev + k2*h\n",
    "    \n",
    "    for i in range(N):\n",
    "        if index_next-int(index_prev_spike[i]) < R_p_ind:\n",
    "            V_neuron_next = tf.tensor_scatter_nd_update(V_neuron_next,[[i]],[[E_L]])\n",
    "        elif np.float64(V_temp[i]) < V_T:\n",
    "            V_neuron_next = tf.tensor_scatter_nd_update(V_neuron_next,[[i]],[[np.float64(V_temp[i])]])\n",
    "        else:\n",
    "            Spike_next    = tf.tensor_scatter_nd_update(V_neuron_next,[[i]],[[int(1)]]) \n",
    "            V_neuron_next = tf.tensor_scatter_nd_update(V_neuron_next,[[i]],[[np.float64(V_temp[i])]])\n",
    "    \n",
    "    return V_neuron_next, Spike_next\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUivuJnhMQV8"
   },
   "source": [
    "### Synaptic Current Solver\n",
    "solves the current input to neuron j due to spike in neuron i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.398250Z",
     "start_time": "2021-10-21T10:55:29.371250Z"
    },
    "id": "pnFsMmB4K65-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 869\n"
     ]
    }
   ],
   "source": [
    "def syn_res(syn_string,type_syn,t,time,i,j,w_ij,del_i,h,M):  \n",
    "    # spike in neuron i, produces a synaptic current in neuron j, weight = w_ij\n",
    "    shape = tf.constant([M])\n",
    "\n",
    "    ts_ds = np.float64(time[t]) + del_i\n",
    "    ind = int(tf.where(time == ts_ds))\n",
    "    \n",
    "    if syn_string == \"static\":\n",
    "        indices = tf.constant([[ind]])\n",
    "        updates = tf.constant([w_ij/h])\n",
    "        syn_curr = tf.scatter_nd(indices, updates, shape)\n",
    "       \n",
    "    elif syn_string == \"first-order\":\n",
    "        tau_s = 4 * h \n",
    "        temp = w_ij * (1/tau_s) * tf.exp(-(1/tau_s)*(time -ts_ds))\n",
    "        updates = temp[ind:M]\n",
    "        indices = tf.constant([[k for k in range(ind,M)]])\n",
    "\n",
    "        syn_curr = tf.scatter_nd(indices, updates, shape)\n",
    "\n",
    "\n",
    "    elif syn_string == \"second-order\":\n",
    "        if type_syn == 1:\n",
    "            tau_s1, tau_s2 = 4, 8\n",
    "        elif type_syn == 0:\n",
    "            tau_s1, tau_s2 = 4, 2\n",
    "        temp = (w_ij/(tau_s1-tau_s2)) * (tf.exp(-(1/tau_s1)*(time -ts_ds)) -tf.exp(-(1/tau_s2)*(time -ts_ds)))\n",
    "        updates = temp[ind:M]\n",
    "        indices = tf.constant([[k for k in range(ind,M)]])\n",
    "        syn_curr = tf.scatter_nd(indices, updates, shape)\n",
    "        \n",
    "            \n",
    "    return syn_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cmVIjCvEYbI"
   },
   "source": [
    "#### Reservoir solver\n",
    "Converted from **MATLAB assignment 3 Q2** neuron solver <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.413252Z",
     "start_time": "2021-10-21T10:55:29.400251Z"
    },
    "id": "koBfFUF2EYbI"
   },
   "outputs": [],
   "source": [
    "def reservoir_solver(N, Delay, synapes, M, h, I_app, threshold, params_potential, **kwargs):\n",
    "#     C_theta, del_c, tau_c, nbits = params_conc.values()\n",
    "    \n",
    "    global Weights\n",
    "\n",
    "    I_syn = tf.zeros((N,M))\n",
    "    I_total = tf.zeros((N,M))\n",
    "    V_neurons = vrest*tf.ones((N,M)) # potential of each neuron at every time instant\n",
    "    Spikes = tf.zeros((N,M))         # 1 if ith neuron spikes at jth time step\n",
    "    # Calcium_conc = tf.zeros((N,M))\n",
    "\n",
    "    syn_string = \"static\"\n",
    "    \n",
    "    index_prev_spike = -1*(M)*tf.ones((N,))\n",
    "\n",
    "    time = tf.convert_to_tensor([j*h for j in range(M)])\n",
    "\n",
    "    for t in range(1,M):\n",
    "        I_total = I_app + I_syn\n",
    "\n",
    "        V_neuron, Spike = LIF(V_neurons[:,t-1],I_total[:,t-1],I_total[:,t],N,h,t,index_prev_spike, params_potential)  # solve for neuron potential and check if spike is produced\n",
    "        indices = [[k,t] for k in range(N)]\n",
    "\n",
    "        V_neurons = tf.tensor_scatter_nd_add(V_neurons,indices=indices,updates=V_neuron)\n",
    "        Spikes = tf.tensor_scatter_nd_add(Spikes,indices=indices,updates=Spike)\n",
    "        \n",
    "        # conc = conc_update(Calcium_conc[:,t-1], Spike, tau_c, h)\n",
    "        # Calcium_conc = tf.tensor_scatter_nd_add(Calcium_conc,indices=indices,updates=conc)\n",
    "\n",
    "        for i in range(N):\n",
    "            if int(Spike[i]) == 1:\n",
    "                index_prev_spike = tf.tensor_scatter_nd_update(index_prev_spike,[[i]],[[1]])\n",
    "                \n",
    "                I_syn_additional = tf.zeros((N,M))\n",
    "                neurons = synapes[i][\"connections\"]\n",
    "                neuron_tp = synapes[i][\"Neuron_type\"]\n",
    "\n",
    "                for j in range(len(neurons)): # iteration over the synapic connection from i to neurons[j]\n",
    "                    updates = syn_res(syn_string,neuron_tp,t,time,i,neurons[j],np.float64(Weights[i,j]),Delay,h,M)\n",
    "                    indices = [[neurons[j], k] for k in range(M) ]\n",
    "                    I_syn_additional = tf.tensor_scatter_nd_add(I_syn_additional,indices=indices,updates=updates)\n",
    "\n",
    "                    # W_new = Weight_learner(last_conc, weight_prev, C_theta,  del_c, nbit, neuron_tp)\n",
    "                    # index = [[i,neurons[j]]]\n",
    "                    # Weights = tf.tensor_scatter_nd_update(Weights,indices=index, updates=[W_new])\n",
    "      \n",
    "        I_syn = I_syn + I_syn_additional\n",
    "\n",
    "    \n",
    "    return V_neurons, Spikes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readout neurons -- Initialization and Solver\n",
    "- Consider **10 classes** for TI subset of Digit classification. So 10 readout neurons for each digit \"0\", \"1\", \"2\"...<br>\n",
    "- The neuron that fires most number of times is the winner and we label it that way for the input.\n",
    "- **Todo:** Teacher signal included, but not in tensorflow\n",
    "- Storing the synapse connections, and creating the initial weight matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.723274Z",
     "start_time": "2021-10-21T10:55:29.417253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Label': '0'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_labels = [str(x) for x in range(10)]\n",
    "N_read = 10                                           # No. of Readout neurons\n",
    "W_init_read = 1                                       # Initial weight, equal for all, update with learning\n",
    "Weights_temp_readOut = np.zeros((N_read, N), dtype='float')\n",
    "\n",
    "\n",
    "synapes_read = [dict() for i in range(N_read)]        # an array of dictonaries which store the label of neuron, \n",
    "                                                      # and the IDs of the neurons it is connected to\n",
    "\n",
    "for l in range(N_read):\n",
    "    label = All_labels[l]\n",
    "    cons = []\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            for k in range(nz):                \n",
    "                Weights_temp_readOut[l,int(LSM_ID[i,j,k])] = W_init_read  \n",
    "                \n",
    "    synapes_read[l] = {\"Label\":label}\n",
    "\n",
    "global Weights_readOut\n",
    "Weights_readOut = tf.convert_to_tensor(Weights_temp_readOut,dtype=tf.float64)\n",
    "Delay = 1                                             #constant delay for all synapses, same for readout neurons also\n",
    "synapes_read[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYhVqXgPEYbJ"
   },
   "source": [
    "Calcium concentration update and Weight learning by calculation of Digitized Calcium concentration updation, **Equations 15 , 16 , 17, 18 in IEEE paper**<br>\n",
    "Parameters are taken from table, not sure about value of nbit yet. P+ and P- values are taken from vivek's paper(2019, IJCNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.738406Z",
     "start_time": "2021-10-21T10:55:29.725276Z"
    },
    "id": "JtpC3gggDscK"
   },
   "outputs": [],
   "source": [
    "def conc_update(prev_conc, Spike, tau_c, h):\n",
    "    return prev_conc*(1 - h/tau_c) + Spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.753543Z",
     "start_time": "2021-10-21T10:55:29.739408Z"
    },
    "id": "sh0nmc_XEYbJ"
   },
   "outputs": [],
   "source": [
    "def Weight_learner(last_conc, weight_prev,\n",
    "                   C_theta=5,  del_c=3, nbit=3, type_syn = None):\n",
    "    \"\"\"\n",
    "        Set type_syn as 1 for E --> E/I and 0 for I --> E/I, basically fanout from I or E.\n",
    "    \"\"\"\n",
    "    \n",
    "    p_plus = 0.1; p_minus = 0.1;\n",
    "    \n",
    "    \n",
    "    # if type_syn not in (1, 0): raise ValueError(\"Invalid type\")\n",
    "    \n",
    "    Wmax = 8 if type_syn==0 else 8*(1 - 2**(nbit - 1))\n",
    "    Wmin = -8 if type_syn==1 else -8*(1 - 2**(nbit - 1))\n",
    "    del_W = 0.0002 * 2**(nbit - 4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (C_theta < last_conc < C_theta + del_c) and (weight_prev < Wmax):\n",
    "        Wnew = weight_prev + del_w if binomial(1, p_plus) == 1 else weight_prev\n",
    "    elif (C_theta - del_c < last_conc < C_theta ) and (weight_prev > Wmin):\n",
    "        Wnew = weight_prev - del_w if binomial(1, p_minus) == 1 else weight_prev\n",
    "    else:\n",
    "        Wnew = weight_prev\n",
    "        \n",
    "        \n",
    "    return new_conc, Wnew\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teacher at each Time Step, parameters **From Classification Section, Vivek(IJCNN)**\n",
    "<img src=\"https://cdn.mathpix.com/snip/images/NpedEkJThKb6bCIxwDmM4awveU8TdyLjolutUQQiKek.original.fullsize.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.769545Z",
     "start_time": "2021-10-21T10:55:29.754547Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def teacher_current(neuron_ids, desired_neuron_ids, Calcium_conc, params_conc):\n",
    "    C_theta, del_c, tau_c, nbits, delta_c = params_conc.values()\n",
    "    \n",
    "    I_teach = np.zeros([N_read,1])\n",
    "    I_infi = 10000\n",
    "    for a_neuron_id in neuron_ids:\n",
    "        if a_neuron_id in desired_neuron_ids:\n",
    "            I_teach[a_neuron_id,1] = I_infi * np.heaviside(C_theta +  delta_c - Calcium_conc[a_neuron_id])\n",
    "        else:\n",
    "            I_teach[a_neuron_id,1] = - I_infi * np.heaviside(Calcium_conc[a_neuron_id] - (C_theta -  delta_c))\n",
    "    \n",
    "    return I_teach         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cmVIjCvEYbI"
   },
   "source": [
    "#### Readout response\n",
    "Converted from **MATLAB assignment 3 Q2** neuron solver <br>\n",
    "- Check pls, there are some changes, also some questions, what is \"threshold\" in arguments of both functions ?\n",
    "- **TODO** Might have messed up indents, indices and tensorflow syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.894895Z",
     "start_time": "2021-10-21T10:55:29.771546Z"
    },
    "id": "koBfFUF2EYbI"
   },
   "outputs": [],
   "source": [
    "def readOut_response(N_read,N, Delay, synapes_read,synapses_res, M, h, spikes_res, threshold, \n",
    "                     params_potential, params_conc,training=False, **kwargs):\n",
    "    C_theta, del_c, tau_c, nbits, delta_c = params_conc.values()\n",
    "    \n",
    "    global Weights_readOut\n",
    "\n",
    "    I_syn = tf.zeros((N_read,M))\n",
    "    I_total = tf.zeros((N_read,M))\n",
    "    V_neurons = vrest*tf.ones((N_read,M)) # potential of each neuron at every time instant\n",
    "    Spikes = tf.zeros((N_read,M))         # 1 if ith neuron spikes at jth time step\n",
    "    Calcium_conc = tf.zeros((N_read,M))\n",
    "    I_teach = tf.zeros((N_read,1))\n",
    "\n",
    "    syn_string = \"static\"\n",
    "    \n",
    "    index_prev_spike = -1*(M)*tf.ones((N_read,))\n",
    "\n",
    "    time = tf.convert_to_tensor([j*h for j in range(M)])\n",
    "    \n",
    "    for t in range(1,M):\n",
    "        I_total = I_syn \n",
    "        I_total[:,t-1] += I_teach\n",
    "        V_neuron, Spike = LIF(V_neurons[:,t-1],I_total[:,t-1],I_total[:,t],N_read,h,t,index_prev_spike, \n",
    "                              params_potential)  # solve for neuron potential and check if spike is produced\n",
    "        indices = [[k,t] for k in range(N_read)]\n",
    "\n",
    "        V_neurons = tf.tensor_scatter_nd_add(V_neurons,indices=indices,updates=V_neuron)\n",
    "        Spikes = tf.tensor_scatter_nd_add(Spikes,indices=indices,updates=Spike)\n",
    "        \n",
    "        conc = conc_update(Calcium_conc[:,t-1], Spike, tau_c, h)\n",
    "        Calcium_conc = tf.tensor_scatter_nd_add(Calcium_conc,indices=indices,updates=conc)\n",
    "        \n",
    "        if training:\n",
    "            neuron_ids = [i for i in range(N_read)]\n",
    "            desired_neuron_ids = [0]\n",
    "            I_teach = teacher_current(neuron_ids, desired_neuron_ids, Calcium_conc, params_conc)\n",
    "        \n",
    "        for i in range(N_read):\n",
    "            if Spikes[i] == 1:\n",
    "                index_prev_spike = tf.tensor_scatter_nd_update(index_prev_spike,[[i]],[[1]])\n",
    "        \n",
    "        for i in range(N):\n",
    "            if spikes_res[i] == 1:\n",
    "                I_syn_additional = tf.zeros((N_read,M))\n",
    "                neuron_tp = synapses_res[i][\"Neuron_type\"]\n",
    "                for j in range(N_read):\n",
    "                    updates = syn_res(syn_string,neuron_tp,t,time,i,j,np.float64(Weights_readOut[j,i]),Delay,h,M)\n",
    "                    indices = [[j, k] for k in range(M)]\n",
    "                    I_syn_additional = tf.tensor_scatter_nd_add(I_syn_additional,indices=indices,updates=updates)\n",
    "\n",
    "                    W_new = Weight_learner(Calcium_conc[j,t-1], Weights_readOut[j,i], C_theta,  del_c, nbit, neuron_tp)\n",
    "                    index = [[j,i]]\n",
    "                    Weights_readOut = tf.tensor_scatter_nd_update(Weights_readOut,indices=index, updates=[W_new])\n",
    "\n",
    "                I_syn = I_syn + I_syn_additional\n",
    "            \n",
    "#             if int(Spike[i]) == 1:\n",
    "#                 index_prev_spike = tf.tensor_scatter_nd_update(index_prev_spike,[[i]],[[1]])\n",
    "                \n",
    "#                 I_syn_additional = tf.zeros((N,M))\n",
    "                \n",
    "                ## No fanout for readout neurons, below part probably is not required\n",
    "                \n",
    "#                 neurons = synapes[i][\"connections\"]\n",
    "#                 neuron_tp = synapes[i][\"Neuron_type\"]\n",
    "\n",
    "#                 for j in range(len(neurons)): # iteration over the synapic connection from i to neurons[j]\n",
    "#                     updates = syn_res(syn_string,neuron_tp,t,time,i,neurons[j],np.float64(Weights[i,j]),Delay,h,M)\n",
    "#                     indices = [[neurons[j], k] for k in range(M) ]\n",
    "#                     I_syn_additional = tf.tensor_scatter_nd_add(I_syn_additional,indices=indices,updates=updates)\n",
    "\n",
    "    return V_neurons, Spikes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:30.003903Z",
     "start_time": "2021-10-21T10:55:29.988901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 870\n"
     ]
    }
   ],
   "source": [
    "def classifier(Spikes_readout,synapes_read):\n",
    "    No_of_spikes = tf.reduce_sum(Spikes_readout,0)\n",
    "    class_out = tf.argmax(No_of_spikes)\n",
    "    return synapes_read[class_out][\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T10:55:29.926901Z",
     "start_time": "2021-10-21T10:55:29.896894Z"
    },
    "id": "yTC7s2c4OpLR"
   },
   "outputs": [],
   "source": [
    "## Connection from input neurons to reservoir\n",
    "L = 86 #no. of input neurons\n",
    "W_in_res = np.zeros((L,N)) # (i,j) entry is the weight of synapse from ith input to jth neuron in reservoir \n",
    "W_in = 8\n",
    "Fin = 4 # no. of neurons a single input neuron is connected to\n",
    "\n",
    "connection_in_res = np.zeros((L,Fin)) # stores the id of reservoir neurons\n",
    "\n",
    "reservoir_ID = np.array([i for i in range(N)])\n",
    "\n",
    "for i in range(L):\n",
    "    shuffle(reservoir_ID)\n",
    "    for j in range(Fin):\n",
    "        sign_W_in = (binomial(1,1/2) - 0.5)*2\n",
    "        W_in_res[i,reservoir_ID[j]] = sign_W_in*W_in\n",
    "        connection_in_res[i,j] = reservoir_ID[j]\n",
    "\n",
    "W_in_res = tf.convert_to_tensor(W_in_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-21T10:55:12.020Z"
    },
    "id": "ilkJStu0QufK"
   },
   "outputs": [],
   "source": [
    "## Current input to the reservoir from the input neurons\n",
    "In_neurons = tf.zeros((L,M))   # spike train of L input neurons, over M timesteps, 1 if spike, 0 if no spike\n",
    "\n",
    "In_app = tf.zeros((N,M))    # input current to the reservoir.\n",
    "\n",
    "time = tf.convert_to_tensor([j*h for j in range(M)])\n",
    "\n",
    "syn_string = \"static\"\n",
    "\n",
    "for t in range(M):\n",
    "    for i in range(L):\n",
    "        if int(In_neurons[i,t]) == 1:\n",
    "            for j in range(Fin):\n",
    "                n_ID = connection_in_res[i,j]\n",
    "                w_ij = W_in_res[i,n_ij]\n",
    "                updates = syn_res(syn_string,1,t,time,i,n_ID,w_ij,Delay,h,M) \n",
    "                indices = [[n_ID,k] for k in range(M)]\n",
    "                In_app = tf.tensor_scatter_nd_add(In_app, indices=indices, updates=updates)\n",
    "\n",
    "# In_app is given as input to the reservoir"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reservoir.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "cb34221c29cbd393528f59737984b7cee90fecb74dfd32a425a37477f31f3c8a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
